{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diff3f import get_features_per_vertex\n",
    "from time import time\n",
    "from utils import convert_mesh_container_to_torch_mesh, cosine_similarity, double_plot, get_colors, generate_colors\n",
    "from dataloaders.mesh_container import MeshContainer\n",
    "from diffusion import init_pipe\n",
    "from dino import init_dino\n",
    "from functional_map import compute_surface_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "torch.cuda.set_device(device)\n",
    "num_views = 100\n",
    "H = 512\n",
    "W = 512\n",
    "num_images_per_prompt = 1\n",
    "tolerance = 0.004\n",
    "random_seed = 42\n",
    "use_normal_map = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(device, pipe, dino_model, m, prompt):\n",
    "    mesh = convert_mesh_container_to_torch_mesh(m, device=device, is_tosca=False)\n",
    "    mesh_vertices = mesh.verts_list()[0]\n",
    "    features = get_features_per_vertex(\n",
    "        device=device,\n",
    "        pipe=pipe, \n",
    "        dino_model=dino_model,\n",
    "        mesh=mesh,\n",
    "        prompt=prompt,\n",
    "        mesh_vertices=mesh_vertices,\n",
    "        num_views=num_views,\n",
    "        H=H,\n",
    "        W=W,\n",
    "        tolerance=tolerance,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        use_normal_map=use_normal_map,\n",
    "    )\n",
    "    return features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niladridutt/miniconda3/envs/cv/lib/python3.10/site-packages/diffusers/configuration_utils.py:239: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'unet_2d_condition.UNet2DConditionModel'>.load_config(...) followed by <class 'unet_2d_condition.UNet2DConditionModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1e53f7c2f945a89c166fa1944d7a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Using cache found in /home/niladridutt/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/niladridutt/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/niladridutt/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/niladridutt/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "pipe = init_pipe(device)\n",
    "dino_model = init_dino(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_path = \"meshes/cow.obj\"\n",
    "target_file_path = \"meshes/camel.obj\"\n",
    "source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niladridutt/miniconda3/envs/cv/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 100/100 [03:07<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  8\n",
      "Time taken in mins:  3.203687043984731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f_source = compute_features(device, pipe, dino_model, source_mesh, \"cow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:05<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  2\n",
      "Time taken in mins:  3.1360365390777587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f_target = compute_features(device, pipe, dino_model, target_mesh, \"camel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "cmap_source = get_colors(source_mesh.vert); cmap_target = cmap_source[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a254e2a8b4c54dbf85a4305da3bc8f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6abcd5e91f1494c9e3b3b19ac0e40a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply functional map on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:17<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  140\n",
      "Time taken in mins:  3.461587341626485\n",
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:14<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  17\n",
      "Time taken in mins:  3.356095306078593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_file_path = \"meshes/cat.off\"\n",
    "target_file_path = \"meshes/lion.off\"\n",
    "source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_file_path)\n",
    "f_source = compute_features(device, pipe, dino_model, source_mesh, \"cat\")\n",
    "f_target = compute_features(device, pipe, dino_model, target_mesh, \"lion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a10a7822ea44c58df924f37eb60e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdc580b77784cd9b41c36a658f4af35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = cosine_similarity(f_source.to(device),f_target.to(device))\n",
    "s = torch.argmax(s, dim=0).cpu().numpy()\n",
    "cmap_source = get_colors(source_mesh.vert); cmap_target = cmap_source[s]\n",
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh1 (7207, 3)\n",
      "mesh2 (5000, 3)\n",
      "\n",
      "Computing Laplacian spectrum\n",
      "Computing 200 eigenvectors\n",
      "\tDone in 0.86 s\n",
      "Computing 200 eigenvectors\n",
      "\tDone in 0.58 s\n",
      "\n",
      "Computing descriptors\n",
      "\tNormalizing descriptors\n",
      "\n",
      "\t2048 out of 2048 possible descriptors kept\n",
      "Computing commutativity operators\n",
      "\tScaling LBO commutativity weight by 8.5e-10\n",
      "\n",
      "Optimization :\n",
      "\t50 Ev on source - 50 Ev on Target\n",
      "\tUsing 2048 Descriptors\n",
      "\tHyperparameters :\n",
      "\t\tDescriptors preservation :1.0e+00\n",
      "\t\tDescriptors commutativity :1.0e-01\n",
      "\t\tLaplacian commutativity :1.0e-02\n",
      "\t\tOrientation preservation :0.0e+00\n",
      "\n",
      "\tTask : CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH, funcall : 16, nit : 13, warnflag : 0\n",
      "\tDone in 4.55 seconds\n"
     ]
    }
   ],
   "source": [
    "surface_map = compute_surface_map(source_file_path, target_file_path, f_source.numpy(), f_target.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e897b5c573c4c308a5bcc904f89ec19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b2a81246f4b059ba4dfa9be06c017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap_source = get_colors(source_mesh.vert); cmap_target = cmap_source[surface_map.cpu().numpy()]\n",
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "k = 6\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(f_source)\n",
    "\n",
    "segments1 = kmeans.predict(f_source)\n",
    "\n",
    "# Apply centroids on another mesh to segment it in a corresponding manner\n",
    "segments2 = kmeans.predict(f_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_colors = generate_colors(k)\n",
    "cmap_source = np.array([segment_colors[j] for j in segments1])\n",
    "cmap_target = np.array([segment_colors[j] for j in segments2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5714172d0044a091955db67de801bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3895ca681fe460d90fd303154cfa5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:13<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  3\n",
      "Time taken in mins:  3.3452319582303365\n",
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:17<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  140\n",
      "Time taken in mins:  3.4606642444928486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_file_path = \"meshes/posed_human.off\"\n",
    "target_file_path = \"meshes/cat.off\"\n",
    "source_mesh = MeshContainer().load_from_file(source_file_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_file_path)\n",
    "f_source = compute_features(device, pipe, dino_model, source_mesh, \"naked human\")\n",
    "f_target = compute_features(device, pipe, dino_model, target_mesh, \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(f_source)\n",
    "\n",
    "segments1 = kmeans.predict(f_source)\n",
    "\n",
    "# Apply centroids on another mesh to segment it in a corresponding manner\n",
    "\n",
    "segments2 = kmeans.predict(f_target)\n",
    "segment_colors = generate_colors(k)\n",
    "cmap_source = np.array([segment_colors[j] for j in segments1])\n",
    "cmap_target = np.array([segment_colors[j] for j in segments2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea622e2ea1f42a29d76c9577ba59bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2d26f7196b49cf900b5e5f1974daf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "double_plot(source_mesh,target_mesh,cmap_source,cmap_target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
